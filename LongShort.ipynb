{"cells":[{"cell_type":"markdown","metadata":{},"source":["                                  Long end Short\n","\n","\n","Estudo de long end short, para ativos que compõem a carteira B3 que tem ticker BOVA11.\n","\n","O importante de ser esta carteira, trabalhar com opções (Derivativos), assim diminuindo risco da estratégia.\n","\n","Foi usado dados MetaTrade5 pois são os que menos apresenta dados nulos e dados faltantes.\n"," \n","Este trabalho foi feito em cima da forma clássica:\n","- Vários períodos de tempo \n","- Cointegração \n","- Dickey-Fuller\n","- Resíduos \n","Conta com gráfico de fácil visualização \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# importando as bibliotecas \n","\n","import datetime as dt\n","import time\n","import numpy as np\n","import pandas as pd\n","import MetaTrader5 as mt5\n","from pandas.io.html import read_html\n","from statsmodels.tsa.stattools import adfuller\n","from statsmodels.regression.linear_model import OLS\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# URL da página da Wikipedia\n","page = 'https://pt.wikipedia.org/wiki/Lista_de_companhias_citadas_no_Ibovespa'\n","\n","# Lê a tabela da página usando pandas\n","table = pd.read_html(page, attrs={'class': 'wikitable'})\n","\n","# Obtém a coluna 'Código' e adiciona '.SA' a cada valor\n","dft = table[0]['Código']\n","#dft = [i + '.SA' for i in dft]\n","\n","print(dft)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Inicializa a conexão com o terminal MetaTrader 5\n","if not mt5.initialize():\n","    print(\"initialize() failed, error code =\", mt5.last_error())\n","\n","# Cria um DataFrame vazio\n","df = pd.DataFrame()\n","\n","# Coleta dados de fechamento para cada ticker na lista\n","for ticker in dft:\n","    rates = mt5.copy_rates_from_pos(ticker, mt5.TIMEFRAME_D1, 0, 250)\n","    dfa = pd.DataFrame(rates)\n","    \n","    \n","    if 'close' in dfa.columns:\n","        df[ticker] = dfa['close']\n","    else:\n","        print(f\"Este ticker '{ticker}' não foi localizado.\")\n","\n","# Coleta dados de fechamento para o ticker 'ITSA4' para parametros\n","rates = mt5.copy_rates_from_pos('ITSA4', mt5.TIMEFRAME_D1, 0, 250)\n","dfa = pd.DataFrame(rates)\n","dfa['time'] = pd.to_datetime(dfa['time'], unit='s')\n","df.set_index(dfa['time'], inplace=True)\n","\n","# Exibe as primeiras linhas do DataFrame\n","print(df.head())\n","\n","# Encerra a conexão com o MetaTrader 5\n","mt5.shutdown()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# não irei usar yahoo finance pois tem muitos dados nulos \n","\n","# URL da página da Wikipedia\n","#page = 'https://pt.wikipedia.org/wiki/Lista_de_companhias_citadas_no_Ibovespa'\n","\n","# Lê a tabela da página usando pandas\n","#table = pd.read_html(page, attrs={'class': 'wikitable'})\n","\n","# Obtém a coluna 'Código' e adiciona '.SA' a cada valor\n","#dft = table[0]['Código']\n","#dft = [i + '.SA' for i in dft]\n","\n","# Criando um DataFrame vazio para armazenar os preços de fechamento ajustados\n","#adj_close_df = pd.DataFrame()\n","\n","# Iterando pelos tickers\n","#for ticker in dft:\n","    #try:\n","        # Obtendo os dados históricos para o ticker\n","        #data = yf.download(ticker, start='2020-01-01', end='2024-03-04')\n","        # Selecionando apenas a coluna 'Adj Close'\n","        #adj_close = data['Adj Close']\n","        # Adicionando os preços de fechamento ajustados ao DataFrame\n","       # adj_close_df[ticker] = adj_close\n","    #except Exception as e:\n","        #print(f\"Erro ao obter dados para o ticker {ticker}: {e}\")\n","\n","# Exibindo o DataFrame com os preços de fechamento ajustados\n","#print(adj_close_df)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Excluindo colunas com valores nulos\n","#adj_close_df = df\n","#adj_close_df = adj_close_df.dropna(axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# criando novas colunas com periodos de tempo \n","\n","df120 = df.iloc[-120:]\n","df140 = df.iloc[-140:]\n","df160 = df.iloc[-160:]\n","df180 = df.iloc[-180:]\n","df200 = df.iloc[-200:]\n","df220 = df.iloc[-220:]\n","df250 = df.iloc[-250:]\n","df.copy()\n","dfs = [df120,df140,df160,df180,df200,df220,df250]\n","for i in dfs:\n","    i.dropna(axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# cointegração entre duas séries temporais (t1 e t2) utilizando o teste de ADF (Augmented Dickey-Fuller).\n","\n","def cointegration(t1,t2,df):\n","    model = OLS(df[t1],df[t2])\n","    model = model.fit()\n","    adf = adfuller(model.resid)\n","    #print('test statistic : {}   ,  p-value : {} \\n'.format(adf[0],adf[1]))\n","    #print('Criticals : {}'.format(adf[4]))\n","    if adf[1] < 0.05:\n","        return True\n","    else:\n","        return False"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# vamos aplicar cointegração em diferentes intervalos de tempo.\n","\n","def get_pairs(): \n","    \n","    pares= []\n","    dfs = [df120,df140,df160,df180,df200,df220,df250]\n","    for ticker1 in dfs[0].columns:\n","        for ticker2 in dfs[0].columns:\n","            aux=[]\n","            if ticker1 == ticker2:\n","                continue\n","            for timeframe in dfs:\n","                c = cointegration(ticker1,ticker2,timeframe)\n","                aux.append(c)\n","            #print(ticker1,ticker2,aux)\n","            if sum(aux) >= 3:\n","                pares.append('{}x{}'.format(ticker1,ticker2))\n","    return pares"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","p = get_pairs()\n","print(p)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# resíduos dos pares\n"," \n","def get_resid(par):\n","    t1 = df[par.split('x')[0]]\n","    t2 = df[par.split('x')[1]]\n","    model = OLS(t1,t2)\n","    model = model.fit()\n","    return model.resid"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#  cointegração entre os ativos e intervalo tempo\n","\n","def cointegration_wtimes(ticker1,ticker2):\n","    l = [120,140,160,180,200,220,250]\n","    aux = {}\n","    for i in range(len(dfs)):\n","        co = cointegration(ticker1,ticker2,dfs[i])\n","        aux[l[i]] = co\n","    return aux\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# definindo limite superior e inferior \n","\n","def entradas(par):\n","    r = get_resid(par)\n","    upper_limit = 2 * r.std()\n","    lower_limit = -2 * r.std()\n","    if r.iloc[-1] > upper_limit or r.iloc[-1] < lower_limit:\n","        return par\n","    else:\n","        return False\n","\n","# Crie uma lista para armazenar os pares de entrada válidos\n","lista_entradas = []\n","for par in p:\n","    a = entradas(par)\n","    if a:\n","        lista_entradas.append(a)\n","\n","print(lista_entradas)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Crie a figura e os eixos\n","fig, ax = plt.subplots(len(lista_entradas), 1, figsize=(10, 20))\n","fig.subplots_adjust(hspace=0.5)\n","\n","# sobre os pares de entrada\n","for i, par in enumerate(lista_entradas):\n","    r = get_resid(par)\n","    sns.lineplot(x=df.index, y=r, ax=ax[i])\n","    ax[i].axhline(y=2*r.std(), color='r', alpha=0.33)\n","    ax[i].axhline(y=-2*r.std(), color='r', alpha=0.33)\n","    ax[i].axhline(y=r.mean(), color='g', alpha=0.33)\n","    ax[i].set_ylabel(\"Spread\")\n","    ax[i].set_xlabel(\"\")\n","    ax[i].set_title(par)\n","\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":2}
